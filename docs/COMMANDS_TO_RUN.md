# Commands to Run - Quick Reference

## All Commands You Can Run

### 1. Evaluate Feature Selection Agent (Fixed!)
```bash
python src/evaluate_feature_selection.py
```
**What it does:** Tests the feature selection agent on test data
**Expected output:**
- Subscription rate: ~1.60%
- Features used: ~0.22 (very few!)
- Top features: Country_ConvRate, Education_ConvRate
**Time:** ~1 minute

---

### 2. Compare Baseline vs Feature Selection
```bash
# First make sure baseline results exist
python src/evaluate.py

# Then run feature selection evaluation
python src/evaluate_feature_selection.py

# Then the comparison will show automatically
```
**What it does:** Shows side-by-side comparison
**Expected output:**
```
Baseline:           1.50% subscription rate (3.4x improvement)
Feature Selection:  1.60% subscription rate (3.6x improvement)
```

---

### 3. Analyze Feature Importance (Already Ran!)
```bash
python src/analyze_features.py
```
**What it does:** Runs 1000 test episodes and tracks which features are selected
**Output file:** `logs/feature_analysis_results.json`
**Key findings:**
- Country_ConvRate: 100% (always used when successful)
- Education_ConvRate: 100%
- Average features used: 13.7 out of 16

---

### 4. Re-train Baseline Agent (If Needed)
```bash
python src/train.py
```
**What it does:** Trains baseline agent (6 actions, 16 features)
**Time:** ~3 minutes for 100k episodes
**Output:** `checkpoints/agent_final.pkl`

---

### 5. Re-train Feature Selection Agent (If Needed)
```bash
python src/train_feature_selection.py
```
**What it does:** Trains feature selection agent (22 actions, 32-dim state)
**Time:** ~28 minutes for 100k episodes
**Output:** `checkpoints/agent_feature_selection_final.pkl`

---

### 6. View Training Progress (During Training)
While training is running, you can see:
- Episode number
- Subscription rate
- Q-table size
- Feature toggles
- Improvement over baseline

---

### 7. Check Results Files

**View test results:**
```bash
# Baseline results
type logs\test_results.json

# Feature selection results
type logs\test_results_feature_selection.json

# Feature analysis
type logs\feature_analysis_results.json
```

**View training history:**
```bash
# Baseline training metrics
type logs\training_metrics_final.json

# Feature selection training metrics
type logs\training_metrics_feature_selection_final.json
```

---

## What Each File Contains

### Results Files (JSON)

#### `logs/test_results.json` (Baseline)
```json
{
  "subscription_rate": 1.50,
  "baseline_sub_rate": 0.44,
  "improvement_factor": 3.4
}
```

#### `logs/test_results_feature_selection.json` (Feature Selection)
```json
{
  "subscription_rate": 1.60,
  "avg_features_selected": 0.22,
  "feature_usage_percentage": 1.4,
  "top_features": [...]
}
```

#### `logs/feature_analysis_results.json` (Feature Importance)
```json
{
  "feature_importance_success": {
    "Country_ConvRate": {"frequency": 11, "percentage": 100.0},
    "Education_ConvRate": {"frequency": 11, "percentage": 100.0}
  },
  "avg_features_success": 13.73
}
```

---

## Quick Analysis Commands

### Compare Performance
```bash
# Show both results side by side
echo "Baseline:"
type logs\test_results.json | findstr "subscription_rate improvement_factor"

echo ""
echo "Feature Selection:"
type logs\test_results_feature_selection.json | findstr "subscription_rate improvement_factor"
```

### View Top Features
```bash
python -c "import json; data=json.load(open('logs/feature_analysis_results.json')); print('\nTop Features:'); [print(f'{i+1}. {k}: {v[\"percentage\"]:.1f}%') for i, (k,v) in enumerate(list(data['feature_importance_success'].items())[:5])]"
```

---

## Understanding the Output

### During Training
```
Episode 10,000 / 100,000
================================================================================
BUSINESS METRICS:
  Subscription Rate: 32.20% (baseline: 0.44%)   ‚Üê HIGH because of oversampling
  Improvement: 73.2x subscriptions               ‚Üê Inflated due to batch sampling

FEATURE SELECTION METRICS:
  Avg Feature Toggles: 14.00                     ‚Üê How many times agent toggles
  Final Features Selected: 0                     ‚Üê 0 or 16 (all or nothing)
```

**Important:** Training subscription rate (30-35%) is HIGH because of oversampling. Real test rate is ~1.5%.

---

### During Evaluation
```
TEST SET RESULTS
================================================================================
BUSINESS METRICS:
  Subscription Rate: 1.60% (baseline: 0.44%)     ‚Üê REAL performance
  Improvement: 3.6x subscriptions                ‚Üê Realistic improvement

FEATURE SELECTION METRICS:
  Avg Features Selected: 0.22 / 16               ‚Üê Uses almost NO features!
  Feature Usage: 1.4%                            ‚Üê Only 1.4% of features
  Data Collection Savings: 98.6%                 ‚Üê Could save 98.6% on data
```

**Important:** Test subscription rate (1.60%) is the REAL performance metric.

---

## Visualizations

### View Training Curves
```bash
# Open in default image viewer
start visualizations\training_curves.png
start visualizations\training_curves_feature_selection.png
```

**What you'll see:**
1. **Episode Rewards** - Should increase over time
2. **Subscription Rate** - Should reach 30-35% (with oversampling)
3. **Epsilon Decay** - Should drop from 1.0 to 0.01
4. **Q-Table Growth** - Should grow to ~1,700 (baseline) or ~500,000 (feature selection)

---

## Common Issues & Fixes

### Issue 1: "File not found" error
**Fix:** Make sure you're in the project directory
```bash
cd c:\Users\krish\Downloads\Sales_Optimization_Agent
```

### Issue 2: "Module not found" error
**Fix:** Activate the virtual environment
```bash
conda activate Sales_Optimization_Agent
```

### Issue 3: JSON serialization error
**Fix:** Already fixed! Just re-run the command
```bash
python src/evaluate_feature_selection.py
```

### Issue 4: Training too slow
**Fix:** Reduce episodes (in train_feature_selection.py, change n_episodes to 10000)

---

## Full Workflow (Start to Finish)

### If Starting Fresh:
```bash
# 1. Activate environment
conda activate Sales_Optimization_Agent

# 2. Process data (if not done)
python src/data_processing.py

# 3. Train baseline
python src/train.py

# 4. Evaluate baseline
python src/evaluate.py

# 5. Train feature selection
python src/train_feature_selection.py

# 6. Evaluate feature selection
python src/evaluate_feature_selection.py

# 7. Analyze features
python src/analyze_features.py
```

### If Already Trained (You Are Here):
```bash
# Just evaluate and analyze
python src/evaluate_feature_selection.py   # ‚Üê Run this now!
python src/analyze_features.py             # Already ran this ‚úì
```

---

## Expected Runtime

| Command | Time |
|---------|------|
| `data_processing.py` | ~10 seconds |
| `train.py` (baseline) | ~3 minutes |
| `evaluate.py` (baseline) | ~30 seconds |
| `train_feature_selection.py` | ~28 minutes |
| `evaluate_feature_selection.py` | ~1 minute |
| `analyze_features.py` | ~1 minute |

---

## Summary

‚úÖ **Training Complete:** Both agents trained successfully
‚úÖ **Analysis Complete:** Feature importance analyzed
‚è≥ **Next Step:** Run `python src/evaluate_feature_selection.py` to get final comparison

Your models are ready to use! üéâ
